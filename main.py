import asyncio
import re
from playwright.async_api import async_playwright

# è¿™é‡Œçš„å…³é”®è¯åªè¦ä½ æ”¹äº†ï¼ŒActions å°±ä¼šè‡ªåŠ¨é‡è·‘
KEYWORDS = ["ğŸ¥¦æ¸¯å°", "ğŸ‡¨ğŸ‡³æ¸¯ğŸ‡­ğŸ‡°å°ğŸ’«ğŸ’«", "è¥¿ç“œğŸ‰", "ç§å¯†", "ç”µæŠ¥"]
OUT_FILE = "bootstrap.min.css"

async def search_task(page, kw):
    try:
        # 1. æ¨¡æ‹Ÿæ‰“å¼€é¦–é¡µ
        await page.goto("https://ox.html-5.me/", wait_until="networkidle", timeout=60000)
        
        # 2. æ¨¡æ‹Ÿå¡«å…¥å…³é”®è¯
        search_input = page.locator('input[name="keyword"]')
        await search_input.fill(kw)
        
        # 3. æ¨¡æ‹ŸæŒ‰ä¸‹å›è½¦ (å¯¹åº”ä½ å›¾é‡Œçš„ç¡®è®¤åŠ¨ä½œ)
        print(f"âŒ¨ï¸  æ­£åœ¨æœç´¢å…³é”®è¯: {kw}")
        await page.keyboard.press("Enter")
        
        # 4. ã€æ ¸å¿ƒç‚¹ã€‘å¼ºåˆ¶ç­‰å¾… 10 ç§’ï¼å“ªæ€•ç½‘ç»œæ…¢ä¹Ÿè¦ç­‰ç»“æœè·³å‡ºæ¥
        await asyncio.sleep(10) 
        
        # 5. æŠ“å–é¡µé¢å†…å®¹
        content = await page.content()
        ids = re.findall(r'/i/(\d+)\.txt', content)
        unique_ids = list(set(ids))
        print(f"ğŸ¯ å…³é”®è¯ [{kw}] æœåˆ° ID åˆ—è¡¨: {unique_ids}")
        return unique_ids
    except Exception as e:
        print(f"âŒ æœç´¢ {kw} è¶…æ—¶æˆ–å¤±è´¥: {e}")
        return []

async def get_content(context, fid):
    page = await context.new_page()
    results = []
    try:
        await page.goto(f"https://ox.html-5.me/i/{fid}.txt", wait_until="networkidle", timeout=30000)
        text = await page.inner_text("body")
        if text:
            for line in text.split('\n'):
                # åªè¦ç¬¦åˆä½ å…³é”®è¯çš„â€œè´§â€
                if any(k in line for k in KEYWORDS) and "http" in line:
                    results.append(line.strip())
    except: pass
    finally: await page.close()
    return results

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        # æ¨¡æ‹Ÿ iPhone 13 çœŸå®ç¯å¢ƒ
        context = await browser.new_context(user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X)")
        page = await context.new_page()

        all_ids = set()
        for kw in KEYWORDS:
            ids = await search_task(page, kw)
            all_ids.update(ids)

        if not all_ids:
            print("âš ï¸ æµè§ˆå™¨æœç´¢ç»“æœä¸ºç©ºï¼Œæ–‡ä»¶å°†ä¸è¿›è¡Œæ›´æ–°ã€‚")
            await browser.close()
            return

        print(f"ğŸ“¡ æ­£åœ¨ç©¿é€æå– {len(all_ids)} ä¸ªæ–‡ä»¶...")
        tasks = [get_content(context, fid) for fid in all_ids]
        extracted_data = await asyncio.gather(*tasks)

        final_sources = set()
        for res in extracted_data:
            for item in res: final_sources.add(item)

        # åˆ†ç±»ä¿å­˜
        with open(OUT_FILE, "w", encoding="utf-8") as f:
            f.write(f"ğŸ“º çœŸå®æµè§ˆå™¨æœç´¢æå–-å…±{len(final_sources)}æ¡,#genre#\n")
            for kw in KEYWORDS:
                group = [l for l in final_sources if kw in l]
                if group:
                    f.write(f"{kw},#genre#\n")
                    for line in sorted(group): f.write(f"{line}\n")
        
        await browser.close()
        print(f"âœ… ä»»åŠ¡å®Œæˆï¼æœ‰æ•ˆæºå·²å†™å…¥ {OUT_FILE}")

if __name__ == "__main__":
    asyncio.run(main())
