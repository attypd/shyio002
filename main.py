import requests, re, concurrent.futures

# ================= è‡ªå®šä¹‰é…ç½®åŒº =================
# 1. æƒ³è¦ä»€ä¹ˆå°å°±å¡«ä»€ä¹ˆè¯ï¼Œæ”¯æŒ ğŸŒ ç­‰ç¬¦å·çš„æ¨¡ç³ŠåŒ¹é…
KEYWORDS = ["æ¸¯å°", "ç¿¡ç¿ ", "å‡¤å‡°", "ç»å…¸", "é‚µæ°", "ç§å¯†", "ä¸€æœ¬é“", "æ˜Ÿç©º", "ç”µå½±"]

# 2. æ‰«ææ·±åº¦ï¼šå¾€å›æ‰«å¤šå°‘ä¸ªæœ€æ–°çš„ç¼–å·
SCAN_DEPTH = 300 
# ===============================================

BASE_URL = "https://ox.html-5.me/i/"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://ox.html-5.me/'
}
OUT_FILE = "bootstrap.min.css"

def get_latest_id():
    """è‡ªåŠ¨è·å–è¯¥ç«™å½“å‰æœ€æ–°çš„æ–‡ä»¶ç¼–å·"""
    try:
        r = requests.get("https://ox.html-5.me/", timeout=10, headers=HEADERS)
        r.encoding = 'utf-8'
        ids = re.findall(r'href="/i/(\d+)\.txt"', r.text)
        if ids:
            return max(map(int, ids))
    except:
        pass
    return 8732100 # å¤‡ç”¨åˆå§‹ç¼–å·

def scan_url(file_id, pattern):
    url = f"{BASE_URL}{file_id}.txt"
    results = []
    try:
        r = requests.get(url, timeout=5, headers=HEADERS)
        r.encoding = 'utf-8' # å¼ºåˆ¶ UTF-8 è§£ç ï¼Œè§£å†³ ğŸŒ ç­‰ç‰¹æ®Šå­—ç¬¦è¯†åˆ«é—®é¢˜
        if r.status_code == 200 and "," in r.text:
            # åŒ¹é… é¢‘é“å,é“¾æ¥ (å…¼å®¹æ‰€æœ‰ç‰¹æ®Šç¬¦å·)
            matches = re.findall(r"([^,\n\r]+),(http[^\s\n\r]+)", r.text)
            for name, link in matches:
                name, link = name.strip(), link.strip()
                if re.search(pattern, name, re.IGNORECASE):
                    results.append(f"{name},{link}")
    except:
        pass
    return results

def main():
    latest_id = get_latest_id()
    start_id = latest_id - SCAN_DEPTH
    print(f"ğŸš€ è‡ªåŠ¨è¿½è¸ªèµ·å§‹ç‚¹: {latest_id}, æ·±åº¦: {SCAN_DEPTH}")
    
    pattern = "|".join(KEYWORDS)
    all_found = []

    # å¹¶å‘æ‰«æ
    with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
        futures = [executor.submit(scan_url, i, pattern) for i in range(start_id, latest_id + 1)]
        for future in concurrent.futures.as_completed(futures):
            res = future.result()
            if res: all_found.extend(res)

    # å†™å…¥æ ‡å‡† TXT æ ¼å¼æ–‡ä»¶
    with open(OUT_FILE, "w", encoding="utf-8") as f:
        if not all_found:
            f.write("âš ï¸ æœªæ‰«æåˆ°æœ‰æ•ˆæº,#genre#\n")
        else:
            # è‡ªåŠ¨åˆ†ç±»å¹¶æŒ‰æ ‡å‡†æ ¼å¼å†™å…¥
            f.write("ğŸ¬ è‡ªåŠ¨æ‰«è¡ç²¾é€‰,#genre#\n")
            unique_list = sorted(list(set(all_found)))
            for line in unique_list:
                f.write(line + "\n")
            
    print(f"âœ… å®Œæˆï¼æ–‡ä»¶å·²ç”Ÿæˆï¼Œå…± {len(all_found)} æ¡æºã€‚")

if __name__ == "__main__":
    main()
